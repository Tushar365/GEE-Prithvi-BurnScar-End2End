{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Prithvi EO 2.0 Burn Scar Dataset Generator\n",
        "\n",
        "This script processes multi-temporal satellite imagery to create training data for\n",
        "the Prithvi EO 2.0 model for burn scar detection and severity classification.\n",
        "\n",
        "Input: GeoTIFF with 13 bands (6 pre-fire, 6 post-fire, 1 label)\n",
        "Output: Temporal image chips and corresponding masks in NumPy format\n",
        "\n",
        "Author: Tushar Thokdar"
      ],
      "metadata": {
        "id": "l5g9i7z2_J5a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BjXEZ7vW_DrZ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import rasterio\n",
        "from tqdm import tqdm\n",
        "from glob import glob\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CONFIGURATION\n",
        "# ============================================================================\n",
        "\n",
        "class Config:\n",
        "    \"\"\"Configuration parameters for dataset generation\"\"\"\n",
        "\n",
        "    # File paths\n",
        "    INPUT_TIF = \"/content/drive/MyDrive/data_in_TIFF/Prithvi_PrePost_Training_Data.tif\"\n",
        "    OUTPUT_DIR = \"prithvi_dataset\"\n",
        "\n",
        "    # Processing parameters\n",
        "    TILE_SIZE = 224\n",
        "    IGNORE_VALUE = 255\n",
        "    EXPECTED_BANDS = 13  # 6 pre + 6 post + 1 label\n",
        "\n",
        "    # Quality thresholds\n",
        "    MIN_VALID_PIXELS = 0.95  # Minimum 95% valid reflectance pixels\n",
        "    MIN_LABELED_PIXELS = 0.01  # Minimum 1% labeled pixels\n",
        "\n",
        "    # Data scaling\n",
        "    REFLECTANCE_SCALE = 10000.0\n",
        "    REFLECTANCE_THRESHOLD = 1.5  # If max > this, apply scaling\n",
        "\n",
        "    # Optional: Include delta (difference) channel\n",
        "    INCLUDE_DELTA = True"
      ],
      "metadata": {
        "id": "NZ6CaW9g_WFL"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# UTILITY FUNCTIONS\n",
        "# ============================================================================\n",
        "\n",
        "def create_output_directories(base_dir: str) -> None:\n",
        "    \"\"\"Create necessary output directories\"\"\"\n",
        "    os.makedirs(f\"{base_dir}/temporal_images\", exist_ok=True)\n",
        "    os.makedirs(f\"{base_dir}/masks\", exist_ok=True)\n",
        "    print(f\"üìÅ Output directories created: {base_dir}/\")\n",
        "\n",
        "\n",
        "def scale_reflectance(data: np.ndarray, scale: float = Config.REFLECTANCE_SCALE) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Scale reflectance values if needed\n",
        "\n",
        "    Args:\n",
        "        data: Input reflectance array\n",
        "        scale: Scaling factor\n",
        "\n",
        "    Returns:\n",
        "        Scaled reflectance array\n",
        "    \"\"\"\n",
        "    if np.nanmax(data) > Config.REFLECTANCE_THRESHOLD:\n",
        "        return data / scale\n",
        "    return data\n",
        "\n",
        "\n",
        "def clean_array(data: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Remove NaN and Inf values from array\n",
        "\n",
        "    Args:\n",
        "        data: Input array\n",
        "\n",
        "    Returns:\n",
        "        Cleaned array with NaN/Inf replaced by 0\n",
        "    \"\"\"\n",
        "    return np.nan_to_num(data, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "\n",
        "\n",
        "def process_label(raw_label: np.ndarray, bad_pixels_mask: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Process raw labels to class indices (0-4) with ignore regions\n",
        "\n",
        "    Args:\n",
        "        raw_label: Raw label array (values 1-5)\n",
        "        bad_pixels_mask: Boolean mask of invalid pixels\n",
        "\n",
        "    Returns:\n",
        "        Processed label array (0-4 for valid, 255 for ignore)\n",
        "    \"\"\"\n",
        "    label = np.full(raw_label.shape, Config.IGNORE_VALUE, dtype=np.uint8)\n",
        "\n",
        "    # Map valid labels from 1-5 to 0-4\n",
        "    valid = (raw_label >= 1) & (raw_label <= 5)\n",
        "    label[valid] = raw_label[valid] - 1\n",
        "\n",
        "    # Mark bad pixels as ignore\n",
        "    label[bad_pixels_mask] = Config.IGNORE_VALUE\n",
        "\n",
        "    return label\n",
        "\n",
        "\n",
        "def passes_quality_checks(bad_pixels_mask: np.ndarray, label: np.ndarray) -> bool:\n",
        "    \"\"\"\n",
        "    Check if chip meets quality thresholds\n",
        "\n",
        "    Args:\n",
        "        bad_pixels_mask: Boolean mask of invalid pixels\n",
        "        label: Processed label array\n",
        "\n",
        "    Returns:\n",
        "        True if chip passes quality checks\n",
        "    \"\"\"\n",
        "    # Check valid pixel percentage\n",
        "    valid_pixel_ratio = (~bad_pixels_mask).mean()\n",
        "    if valid_pixel_ratio < Config.MIN_VALID_PIXELS:\n",
        "        return False\n",
        "\n",
        "    # Check labeled pixel percentage\n",
        "    labeled_pixel_ratio = (label != Config.IGNORE_VALUE).mean()\n",
        "    if labeled_pixel_ratio < Config.MIN_LABELED_PIXELS:\n",
        "        return False\n",
        "\n",
        "    return True\n",
        "\n"
      ],
      "metadata": {
        "id": "ol-ktaep_ZB7"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# MAIN PROCESSING FUNCTION\n",
        "# ============================================================================\n",
        "\n",
        "def generate_dataset(config: Config = Config()) -> int:\n",
        "    \"\"\"\n",
        "    Generate training dataset from multi-temporal satellite imagery\n",
        "\n",
        "    Args:\n",
        "        config: Configuration object\n",
        "\n",
        "    Returns:\n",
        "        Number of chips generated\n",
        "    \"\"\"\n",
        "    print(\"üöÄ Starting Prithvi EO 2.0 Dataset Generation\")\n",
        "    print(f\"   Input: {config.INPUT_TIF}\")\n",
        "    print(f\"   Output: {config.OUTPUT_DIR}\")\n",
        "    print(f\"   Tile size: {config.TILE_SIZE}x{config.TILE_SIZE}\")\n",
        "    print(f\"   Delta channel: {'Enabled' if config.INCLUDE_DELTA else 'Disabled'}\")\n",
        "    print(\"-\" * 70)\n",
        "\n",
        "    # Create output directories\n",
        "    create_output_directories(config.OUTPUT_DIR)\n",
        "\n",
        "    chip_count = 0\n",
        "\n",
        "    with rasterio.open(config.INPUT_TIF) as src:\n",
        "        height, width = src.height, src.width\n",
        "\n",
        "        # Validate input bands\n",
        "        if src.count != config.EXPECTED_BANDS:\n",
        "            raise ValueError(\n",
        "                f\"Expected {config.EXPECTED_BANDS} bands, got {src.count}\"\n",
        "            )\n",
        "\n",
        "        print(f\"üìä Image dimensions: {height}x{width}\")\n",
        "        print(f\"üî¢ Processing {src.count} bands\")\n",
        "        print()\n",
        "\n",
        "        # Process tiles\n",
        "        total_tiles = ((height - config.TILE_SIZE) // config.TILE_SIZE + 1) * \\\n",
        "                      ((width - config.TILE_SIZE) // config.TILE_SIZE + 1)\n",
        "\n",
        "        with tqdm(total=total_tiles, desc=\"Generating chips\") as pbar:\n",
        "            for row in range(0, height - config.TILE_SIZE + 1, config.TILE_SIZE):\n",
        "                for col in range(0, width - config.TILE_SIZE + 1, config.TILE_SIZE):\n",
        "\n",
        "                    # Read tile\n",
        "                    window = rasterio.windows.Window(\n",
        "                        col, row, config.TILE_SIZE, config.TILE_SIZE\n",
        "                    )\n",
        "                    data = src.read(window=window)  # (13, 224, 224)\n",
        "\n",
        "                    # Split bands\n",
        "                    pre_fire = data[0:6].astype(np.float32)\n",
        "                    post_fire = data[6:12].astype(np.float32)\n",
        "                    raw_label = data[12]\n",
        "\n",
        "                    # Scale reflectance if needed\n",
        "                    pre_fire = scale_reflectance(pre_fire)\n",
        "                    post_fire = scale_reflectance(post_fire)\n",
        "\n",
        "                    # Identify bad pixels\n",
        "                    bad_pixels = ~np.isfinite(pre_fire).all(axis=0)\n",
        "\n",
        "                    # Clean arrays\n",
        "                    pre_fire = clean_array(pre_fire)\n",
        "                    post_fire = clean_array(post_fire)\n",
        "\n",
        "                    # Process labels\n",
        "                    label = process_label(raw_label, bad_pixels)\n",
        "\n",
        "                    # Quality checks\n",
        "                    if not passes_quality_checks(bad_pixels, label):\n",
        "                        pbar.update(1)\n",
        "                        continue\n",
        "\n",
        "                    # Create temporal stack\n",
        "                    if config.INCLUDE_DELTA:\n",
        "                        # Calculate change\n",
        "                        delta = np.clip(post_fire - pre_fire, -1.0, 1.0)\n",
        "                        temporal = np.stack([pre_fire, post_fire, delta], axis=0)\n",
        "                        # Clip reflectance channels only\n",
        "                        temporal[0:2] = np.clip(temporal[0:2], 0, 1)\n",
        "                    else:\n",
        "                        temporal = np.stack([pre_fire, post_fire], axis=0)\n",
        "                        temporal = np.clip(temporal, 0, 1)\n",
        "\n",
        "                    temporal = temporal.astype(np.float32)\n",
        "\n",
        "                    # Save chip\n",
        "                    np.save(\n",
        "                        f\"{config.OUTPUT_DIR}/temporal_images/chip_{chip_count:06d}.npy\",\n",
        "                        temporal\n",
        "                    )\n",
        "                    np.save(\n",
        "                        f\"{config.OUTPUT_DIR}/masks/chip_{chip_count:06d}.npy\",\n",
        "                        label\n",
        "                    )\n",
        "\n",
        "                    chip_count += 1\n",
        "                    pbar.update(1)\n",
        "\n",
        "    print()\n",
        "    print(\"‚úÖ Dataset generation complete!\")\n",
        "    print(f\"üì¶ Total chips generated: {chip_count}\")\n",
        "    print(f\"üìÇ Location: {config.OUTPUT_DIR}/\")\n",
        "\n",
        "    return chip_count"
      ],
      "metadata": {
        "id": "1MX_8hJu_fs7"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# DATASET ANALYSIS\n",
        "# ============================================================================\n",
        "\n",
        "def analyze_dataset(dataset_dir: str) -> dict:\n",
        "    \"\"\"\n",
        "    Analyze generated dataset for class distribution and statistics\n",
        "\n",
        "    Args:\n",
        "        dataset_dir: Path to dataset directory\n",
        "\n",
        "    Returns:\n",
        "        Dictionary containing dataset statistics\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(\"üìä DATASET ANALYSIS\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    mask_files = glob(f\"{dataset_dir}/masks/*.npy\")\n",
        "\n",
        "    if not mask_files:\n",
        "        print(\"‚ö†Ô∏è  No mask files found!\")\n",
        "        return {}\n",
        "\n",
        "    # Collect all labels\n",
        "    all_labels = []\n",
        "    for mask_file in tqdm(mask_files, desc=\"Analyzing masks\"):\n",
        "        mask = np.load(mask_file)\n",
        "        valid_pixels = mask != Config.IGNORE_VALUE\n",
        "        all_labels.extend(mask[valid_pixels].tolist())\n",
        "\n",
        "    # Calculate statistics\n",
        "    label_counts = Counter(all_labels)\n",
        "    total_pixels = len(all_labels)\n",
        "\n",
        "    print(f\"\\nüìà Class Distribution:\")\n",
        "    print(f\"{'Class':<15} {'Count':<12} {'Percentage':<12}\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    class_names = {\n",
        "        0: \"Unburned\",\n",
        "        1: \"Low Severity\",\n",
        "        2: \"Moderate-Low\",\n",
        "        3: \"Moderate-High\",\n",
        "        4: \"High Severity\"\n",
        "    }\n",
        "\n",
        "    stats = {}\n",
        "    for class_id in sorted(label_counts.keys()):\n",
        "        count = label_counts[class_id]\n",
        "        percentage = (count / total_pixels) * 100\n",
        "        class_name = class_names.get(class_id, f\"Class {class_id}\")\n",
        "        print(f\"{class_name:<15} {count:<12,} {percentage:<12.2f}%\")\n",
        "        stats[class_name] = {\"count\": count, \"percentage\": percentage}\n",
        "\n",
        "    print(\"-\" * 40)\n",
        "    print(f\"{'Total':<15} {total_pixels:<12,} {100.0:<12.2f}%\")\n",
        "\n",
        "    # Load and check first sample\n",
        "    print(f\"\\nüîç Sample Data Check:\")\n",
        "    sample_img = np.load(f\"{dataset_dir}/temporal_images/chip_000000.npy\")\n",
        "    sample_mask = np.load(f\"{dataset_dir}/masks/chip_000000.npy\")\n",
        "\n",
        "    print(f\"   Image shape: {sample_img.shape}\")\n",
        "    print(f\"   Image range: [{sample_img.min():.4f}, {sample_img.max():.4f}]\")\n",
        "    print(f\"   Mask unique values: {np.unique(sample_mask)}\")\n",
        "\n",
        "    if Config.INCLUDE_DELTA:\n",
        "        print(f\"   Delta channel range: [{sample_img[2].min():.4f}, {sample_img[2].max():.4f}]\")\n",
        "\n",
        "    stats['total_samples'] = len(mask_files)\n",
        "    stats['total_pixels'] = total_pixels\n",
        "\n",
        "    return stats"
      ],
      "metadata": {
        "id": "sTTBvjbE_jwg"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# MAIN EXECUTION\n",
        "# ============================================================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Generate dataset\n",
        "    num_chips = generate_dataset()\n",
        "\n",
        "    # Analyze results\n",
        "    if num_chips > 0:\n",
        "        analyze_dataset(Config.OUTPUT_DIR)\n",
        "\n",
        "        print(\"\\n\" + \"=\" * 70)\n",
        "        print(\"üíæ Next Steps:\")\n",
        "        print(\"=\" * 70)\n",
        "        print(\"1. Review the class distribution above\")\n",
        "        print(\"2. Zip the dataset for backup/sharing:\")\n",
        "        print(f\"   !zip -r prithvi_dataset.zip {Config.OUTPUT_DIR}/\")\n",
        "        print(\"3. Copy to Google Drive (if applicable):\")\n",
        "        print(f\"   !cp prithvi_dataset.zip /content/drive/MyDrive/\")\n",
        "        print(\"=\" * 70)\n",
        "    else:\n",
        "        print(\"\\n‚ö†Ô∏è  No chips were generated. Please check your input data and thresholds.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p1xanaZ8_tTk",
        "outputId": "4bbcad6f-34ec-4392-ca7d-77316bc9dc3b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ Starting Prithvi EO 2.0 Dataset Generation\n",
            "   Input: /content/drive/MyDrive/data_in_TIFF/Prithvi_PrePost_Training_Data.tif\n",
            "   Output: prithvi_dataset\n",
            "   Tile size: 224x224\n",
            "   Delta channel: Enabled\n",
            "----------------------------------------------------------------------\n",
            "üìÅ Output directories created: prithvi_dataset/\n",
            "üìä Image dimensions: 2785x2228\n",
            "üî¢ Processing 13 bands\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating chips: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 108/108 [00:05<00:00, 20.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚úÖ Dataset generation complete!\n",
            "üì¶ Total chips generated: 108\n",
            "üìÇ Location: prithvi_dataset/\n",
            "\n",
            "======================================================================\n",
            "üìä DATASET ANALYSIS\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Analyzing masks: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 108/108 [00:00<00:00, 1169.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìà Class Distribution:\n",
            "Class           Count        Percentage  \n",
            "----------------------------------------\n",
            "Unburned        1,369,197    27.00       %\n",
            "Low Severity    771,342      15.21       %\n",
            "Moderate-Low    924,961      18.24       %\n",
            "Moderate-High   822,241      16.22       %\n",
            "High Severity   1,182,633    23.32       %\n",
            "----------------------------------------\n",
            "Total           5,070,374    100.00      %\n",
            "\n",
            "üîç Sample Data Check:\n",
            "   Image shape: (3, 6, 224, 224)\n",
            "   Image range: [-0.3542, 0.4540]\n",
            "   Mask unique values: [  0   1   2   3   4 255]\n",
            "   Delta channel range: [-0.3542, 0.1316]\n",
            "\n",
            "======================================================================\n",
            "üíæ Next Steps:\n",
            "======================================================================\n",
            "1. Review the class distribution above\n",
            "2. Zip the dataset for backup/sharing:\n",
            "   !zip -r prithvi_dataset.zip prithvi_dataset/\n",
            "3. Copy to Google Drive (if applicable):\n",
            "   !cp prithvi_dataset.zip /content/drive/MyDrive/\n",
            "======================================================================\n"
          ]
        }
      ]
    }
  ]
}